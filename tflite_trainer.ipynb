{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define constants\n",
    "BASE_DIR = './dataset/train'\n",
    "\n",
    "# * Number of times we are going to run through the entire dataset.\n",
    "EPOCHS = 10  \n",
    "# * the image size that we are going to set the images in the dataset to.\n",
    "IMAGE_SIZE = 224\n",
    "# * the number of images we are inputting into the neural network at once.\n",
    "BATCH_SIZE = 64\n",
    "IMAGE_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "\n",
    "RESULT_LABELS = 'results/labels.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data generator with data augmentation techniques such as rotation, shifting and flipping\n",
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "    rescale=1./255,  # rescale pixel values to [0,1]\n",
    "    validation_split=0.2,  # reserve some data for validation\n",
    "    rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=True,  # randomly flip images\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate training data\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    BASE_DIR,\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    subset='training'  # specify this is training data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate validation data\n",
    "val_generator = datagen.flow_from_directory(\n",
    "    BASE_DIR,\n",
    "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    subset='validation'  # specify this is validation data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',  # monitor the validation loss\n",
    "    patience=5,  # number of epochs with no improvement after which training will be stopped\n",
    "    verbose=1,  # report the early stopping events\n",
    "    restore_best_weights=True  # restore the best weights from the monitored quantity\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss',  # monitor the validation loss\n",
    "    factor=0.2,  # factor by which the learning rate will be reduced\n",
    "    patience=3,  # number of epochs with no improvement after which learning rate will be reduced\n",
    "    verbose=1,  # report the lr reduction events\n",
    "    min_lr=0.0001  # lower bound on the learning rate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print and save the class indices\n",
    "print(train_generator.class_indices)\n",
    "labels = '\\n'.join(sorted(train_generator.class_indices.keys()))\n",
    "with open(RESULT_LABELS, 'w') as f:\n",
    "    f.write(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the device strategy\n",
    "strategy = tf.distribute.OneDeviceStrategy(\"GPU:0\")\n",
    "\n",
    "# Define the model within the strategy scope\n",
    "with strategy.scope():\n",
    "    base_model = tf.keras.applications.MobileNetV2(\n",
    "        input_shape=IMAGE_SHAPE,\n",
    "        include_top=False,  # exclude the top layer\n",
    "    )\n",
    "    base_model.trainable = False  # freeze the base model\n",
    "\n",
    "    # Define the custom top layers\n",
    "    model = tf.keras.Sequential([\n",
    "        base_model,\n",
    "        tf.keras.layers.Conv2D(64, 3, activation='relu'),  # increased filter size for more complex patterns\n",
    "        tf.keras.layers.BatchNormalization(),  # normalize the activations of the previous layer at each batch\n",
    "        tf.keras.layers.Dropout(0.2),  # randomly set a fraction rate of input units to 0 at each update during training\n",
    "        tf.keras.layers.Conv2D(64, 3, activation='relu'),  # another convolutional layer\n",
    "        tf.keras.layers.BatchNormalization(),  # batch normalization layer\n",
    "        tf.keras.layers.GlobalAveragePooling2D(),  # apply average pooling on the spatial dimensions until each spatial dimension is one\n",
    "        tf.keras.layers.Dense(128, activation='relu'),  # dense layer with more neurons\n",
    "        tf.keras.layers.Dense(36, activation='softmax')  # final softmax layer\n",
    "    ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.001),  # use Adam optimizer with initial learning rate 0.001\n",
    "        loss='categorical_crossentropy',  # use categorical cross entropy as the loss function\n",
    "        metrics=['accuracy']  # use accuracy as the metric\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[early_stopping, reduce_lr]  # add the callbacks to the training process\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "saved_model_dir = 'results'\n",
    "tf.saved_model.save(model, saved_model_dir)\n",
    "\n",
    "# Convert the model to TensorFlow Lite\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TFLite model\n",
    "with open('results/model.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter_notebook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
