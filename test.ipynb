{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import imghdr # DeprecationWarning: \n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import List, Tuple, Dict, Any, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'data'\n",
    "IMAGE_EXTENSIONS = [\"JPEG\", \"PNG\", \"GIF\", \"BMP\"]\n",
    "LOG_DIR = 'logs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize_images(files: List[str]) -> None:\n",
    "    \n",
    "    deleted_files = 0  # counter for deleted files\n",
    "    \n",
    "    for filename in os.listdir(files):\n",
    "        file_path = os.path.join(files, filename)\n",
    "\n",
    "        try:\n",
    "            with Image.open(file_path) as img:\n",
    "                if img.format not in IMAGE_EXTENSIONS:\n",
    "                    print(f'Deleting (not a valid format) --> {filename}')\n",
    "                    os.remove(file_path)\n",
    "                    deleted_files += 1\n",
    "                    continue\n",
    "                print(filename, img.format, \"%dx%d\" % img.size, img.mode)\n",
    "        except IOError:\n",
    "            print(f'Deleting --> {filename}')\n",
    "            os.remove(file_path)\n",
    "            deleted_files += 1  # increment the counter\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            x = cv2.imread(file_path)\n",
    "            if x is None:\n",
    "                print(f'Deleting: cannot be read by CV2 - {filename}')\n",
    "                os.remove(file_path)\n",
    "                continue\n",
    "        except Exception as e:\n",
    "            print(f'Deleting: cannot be read by CV2 - {filename}')\n",
    "            os.remove(file_path)\n",
    "            continue\n",
    "        \n",
    "\n",
    "        try:\n",
    "            # Get file size in KB\n",
    "            file_size = os.path.getsize(file_path) / 1024  # in KB\n",
    "            if file_size < 10:\n",
    "                print(f'Deleting (less than 10KB) --> {filename}')\n",
    "                os.remove(file_path)\n",
    "                deleted_files += 1  # increment the counter\n",
    "                continue\n",
    "        except Exception as e:\n",
    "            print(f'Deleting: cannot get file size - {filename}')\n",
    "            os.remove(file_path)\n",
    "            continue\n",
    "            \n",
    "    print(f'Total deleted files: {deleted_files}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the `data` directory and clean up data\n",
    "for directory in os.listdir(DATA_DIR):\n",
    "    print(f'--> Cleaning up {directory} directory <--')\n",
    "    directory: List[str] = os.path.join(DATA_DIR, directory)\n",
    "    sanitize_images(directory)\n",
    "    print(f'--> Done cleaning up {directory} directory <--')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid OOM error by setting GPU Memory Growth\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.keras.utils.image_dataset_from_directory('data')\n",
    "data_iter = data.as_numpy_iterator()\n",
    "batch = data_iter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample batch images\n",
    "fig, ax = plt.subplots(ncols=4,figsize=(20, 20))\n",
    "for i, img in enumerate(batch[0][:4]):\n",
    "    ax[i].imshow(img.astype(np.uint8))\n",
    "    ax[i].title.set_text(f'label: {batch[1][i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data = data.map(lambda x, y: (x / 255.0, y))\n",
    "# data = data.map(lambda x, y: (tf.image.resize(x, (224, 224)), y))\n",
    "# data = data.map(lambda x, y: (tf.keras.applications.mobilenet_v2.preprocess_input(x), y))\n",
    "# data = data.map(lambda x, y: (tf.keras.applications.resnet50.preprocess_input(x), y))\n",
    "scaled_iterator = scaled_data.as_numpy_iterator()\n",
    "scaled_batch = scaled_iterator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=4,figsize=(20, 20))\n",
    "for i, img in enumerate(scaled_batch[0][:4]):\n",
    "    ax[i].imshow(img)\n",
    "    ax[i].title.set_text(f'label: {scaled_batch[1][i]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(scaled_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(scaled_batch)*0.7)+1\n",
    "val_size = int(len(scaled_batch)*0.2 )+1\n",
    "test_size= int( len(scaled_batch)*0.1)+1\n",
    "print(train_size, val_size, test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data.take(train_size)\n",
    "val = data.skip(train_size).take(val_size)\n",
    "test = data.skip(train_size+val_size).take(test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Deep Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.1 Build Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(16, (3,3), 1, activation='relu', input_shape=(256, 256, 3)))\n",
    "model.add(MaxPooling2D(2))\n",
    "\n",
    "model.add(Conv2D(32, (3,3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(16, (3,3), 1, activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=tf.losses.BinaryFocalCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=LOG_DIR, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(train, epochs=20, validation_data=val, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.3 Plot Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(hist.history['loss'], color='teal', label='loss')\n",
    "plt.plot(hist.history['val_loss'], color='orange', label='validation_loss')\n",
    "fig.suptitle('Loss', fontsize=20)\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure( )\n",
    "plt.plot(hist.history['accuracy'], color='teal', label='accuracy')\n",
    "plt.plot(hist.history['val_accuracy'], color='orange', label='validation_accuracy')\n",
    "fig.suptitle('Accuracy', fontsize=20)\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = Precision()\n",
    "re = Recall()\n",
    "acc = BinaryAccuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in test.as_numpy_iterator():\n",
    "    x, y = batch\n",
    "    y_pred = model.predict(x)\n",
    "    pre.update_state(y, y_pred)\n",
    "    re.update_state(y, y_pred)\n",
    "    acc.update_state(y, y_pred)\n",
    "print(f'Precision: {pre.result().numpy()}, Recall: {re.result().numpy()}, Accuracy: {acc.result().numpy()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = cv2.imread('data/happy/who-is-happier.jpg')\n",
    "# img = cv2.imread('data/sad/secret-signs-of-loneliness-01-1440x810.jpg')\n",
    "# plt.imshow(img)\n",
    "# plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resized_img = cv2.resize(img, (256, 256))\n",
    "# plt.imshow(cv2.cvtColor(resized_img, cv2.COLOR_BGR2RGB))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.expand_dims(resized_img, 0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction = model.predict(np.expand_dims(resized_img/255, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(prediction)\n",
    "# if prediction > 0.5:\n",
    "#     print('Happy')\n",
    "# else:\n",
    "#     print('Sad')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
